{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  Diversos algoritmos son sensibles a la escala en la que viene cada feature. **Re-escalarlos** puede traer significativas mejoras de rendimiento.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen distintas estrategias de escalamiento de tus features, pero **la más común es la estandarización** donde convertimos la variable para que la distribución de esta siga una distribución que es Gaussiana de media 0 y de desviación estandar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = pd.read_csv('../vol/intermediate_results/X.csv')\n",
    "X = pd.read_csv('X.csv')\n",
    "y = X['worldwide_gross']\n",
    "X = X.drop('worldwide_gross',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3.34293486e+07, 2.00218055e+03, 2.12349130e+00, 1.08203717e+02,\n",
       "       1.04586062e+04, 3.72997042e+07, 6.46046134e+00])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# los promedios de c/u de las features\n",
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.13953290e+07, 1.19684855e+01, 7.20578759e-01, 2.27383598e+01,\n",
       "       2.00144270e+04, 6.58531187e+07, 1.06722362e+00])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# desviacion standard\n",
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4.25000000e+08, 2.00900000e+03, 1.78000000e+00, ...,\n",
       "        4.83400000e+03, 2.37000000e+08, 7.90000000e+00],\n",
       "       [3.06000000e+08, 2.00213073e+03, 2.12697615e+00, ...,\n",
       "        1.43000000e+02, 4.04553863e+07, 7.10000000e+00],\n",
       "       [3.00000000e+08, 2.00700000e+03, 2.35000000e+00, ...,\n",
       "        4.83500000e+04, 3.00000000e+08, 7.10000000e+00],\n",
       "       ...,\n",
       "       [7.00000000e+03, 2.00500000e+03, 2.12697615e+00, ...,\n",
       "        9.30000000e+01, 3.25000000e+03, 7.80000000e+00],\n",
       "       [3.96700000e+03, 2.01200000e+03, 2.35000000e+00, ...,\n",
       "        2.38600000e+03, 4.04553863e+07, 6.30000000e+00],\n",
       "       [1.10000000e+03, 2.00400000e+03, 1.85000000e+00, ...,\n",
       "        1.63000000e+02, 1.10000000e+03, 6.60000000e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.74475428,  0.15201973,  0.00483619, ..., -0.51360982,\n",
       "         0.04792001,  1.34886319],\n",
       "       [ 0.3278305 , -1.01771891, -0.37954393, ..., -0.41782891,\n",
       "         0.95212341, -0.33775615],\n",
       "       [-0.77132733,  0.23557249, -0.64322087, ..., -0.47963433,\n",
       "        -0.54362959,  0.2244503 ],\n",
       "       ...,\n",
       "       [-0.73509136,  0.73688905,  0.31434274, ..., -0.46014838,\n",
       "        -0.52085163, -0.33775615],\n",
       "       [ 0.01378541, -0.18219131,  0.31434274, ..., -0.43371745,\n",
       "        -0.05010703, -0.80626152],\n",
       "       [ 0.11041467,  0.48623077,  0.31434274, ...,  0.2515882 ,\n",
       "         0.26878447,  0.03704815]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMAR TODOS LOS DATOS \n",
    "X_train_scaled, X_test_scaled = (scaler.transform(X_train), scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# model normal\n",
    "model = Lasso()\n",
    "# modelo scalado\n",
    "model_scaled = Lasso()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "model_scaled.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5659488355530882\n0.5659488524114811\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test,y_test))\n",
    "print(model_scaled.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  Los modelos de regresión no se ven afectados por el escalamiento de las features. Los de clasificación sí. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplificar las transformaciones con pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Para hacer tu código más reproducible, y para evitar tener que aplicar multiples veces una misma transformación te recomendamos utilizar <code> sklearn.pipeline.make_pipeline </code> que permite encadenar transformaciones a tus modelos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('lasso', Lasso())])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_scaled = make_pipeline(StandardScaler(),\n",
    "                            Lasso())\n",
    "\n",
    "model_scaled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5659488524114811\n"
     ]
    }
   ],
   "source": [
    "print(model_scaled.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear nuevas features de forma automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "A = np.arange(6).reshape(3, 2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "transformer = PolynomialFeatures(2)\n",
    "transformer.fit_transform(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``PolynomialFeatures`` transforma una matriz $(A1,A2)$ a $(1,A1,A2,A1^2,A1\\cdot A2,A2^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4104, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4104, 36)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# tranformamos a mayor numero de columnas\n",
    "transformer = PolynomialFeatures(2)\n",
    "transformer.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-3.1111346894886376"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model_poly = make_pipeline(PolynomialFeatures(2),\n",
    "                          Lasso())\n",
    "model_poly.fit(X_train,y_train)\n",
    "model_poly.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5659488355530882"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "model = Lasso()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear features categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  En terminos de Machine Learning a las features que pueden tomar un número finito de valores se les llama categóricas. Ejemplos para esto són: género, páis, grado académico, etc.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un mapeo del tipo $\\{Perú, Chile, Colombia, Venezuela\\} \\rightarrow \\{1, 2, 3, 4\\}$ tiene el problema de asignarle un ordén a los valores posibles de la categoría. Este orden impacta de distintas maneras los algoritmos de Machine Learning, por ejemplo aquellos que dependen de la topología de $R^n$ y de la función de distancia entre puntos en este espacio, considerarán que ciertas categorías se encuentran más cercanas unas de otras, siendo que esto es generado puramente artificialmente por el encoding, y no por las datos per se. \n",
    "\n",
    "Para no introducir información falsa o erronéa en nuestro modelos existen formas más inteligentes de encodear nuestros datos.\n",
    "\n",
    "_**Encoding one-hot**_\n",
    "\n",
    "Este encoding consiste en asignarle una columna a cada categoría y rellenarla con 0 y 1 de la forma siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        pais  genero\n",
       "0      Chile  hombre\n",
       "1   Colombia   mujer\n",
       "2   Colombia  hombre\n",
       "3  Venezuela   mujer"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pais</th>\n      <th>genero</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chile</td>\n      <td>hombre</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Colombia</td>\n      <td>mujer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Colombia</td>\n      <td>hombre</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Venezuela</td>\n      <td>mujer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "d = pd.DataFrame([['Chile','Colombia','Colombia','Venezuela'],['hombre','mujer','hombre','mujer']])\n",
    "d = d.T\n",
    "d.columns = pd.Index(['pais','genero']) # da nombre a las columnas\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pais_Chile  pais_Colombia  pais_Venezuela  genero_hombre  genero_mujer\n",
       "0           1              0               0              1             0\n",
       "1           0              1               0              0             1\n",
       "2           0              1               0              1             0\n",
       "3           0              0               1              0             1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pais_Chile</th>\n      <th>pais_Colombia</th>\n      <th>pais_Venezuela</th>\n      <th>genero_hombre</th>\n      <th>genero_mujer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "pd.get_dummies(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn también ofrece un objeto OneHotEncoder pero es un poco más díficil de utilizar, así que por criterios pedagogicos hemos elegido ``pd.get_dummies``. Sin embargo el objeto de sklearn tiene la ventaja de ser pipeable, por lo que es bueno considerarlo para ciertos casos de uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas columnas generaríamos con un one-hot encoding de nuestras features categóricas?\n",
    "https://github.com/JuanPabloMF/datasets-platzi-course "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_obj = pd.read_csv('movies_obj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "color                2\n",
       "content_rating      18\n",
       "language            47\n",
       "country             65\n",
       "genres             914\n",
       "actor_1_name      2097\n",
       "director_name     2398\n",
       "actor_2_name      3032\n",
       "actor_3_name      3521\n",
       "plot_keywords     4760\n",
       "movie_title       4917\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# VER CUANTAS CATEGORIAS HAY:\n",
    "# pd.Series.nunique : Cuenta las unidades\n",
    "movies_obj.apply(pd.Series.nunique).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las features más informativas son las del casting. Si embargo haciendo un one-hot encoding de estas estaríamos aumentando la dimensión por 2000 y algo!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Binario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica no es canónica por lo que tendremos que buscarla en otra librería. Sin embargo el autor tuvo la buena idea de hacer su API compatible con la de sklearn, así que no tendremos ninguna dificultad en usarla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Categoria \\rightarrow Numero \\rightarrow Binario \\rightarrow Columnas $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: category_encoders in /home/infinity/anaconda3/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/infinity/anaconda3/lib/python3.8/site-packages (from category_encoders) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/infinity/anaconda3/lib/python3.8/site-packages (from category_encoders) (0.23.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/infinity/anaconda3/lib/python3.8/site-packages (from category_encoders) (1.5.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /home/infinity/anaconda3/lib/python3.8/site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/infinity/anaconda3/lib/python3.8/site-packages (from category_encoders) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /home/infinity/anaconda3/lib/python3.8/site-packages (from category_encoders) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/infinity/anaconda3/lib/python3.8/site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/infinity/.local/lib/python3.8/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: six in /home/infinity/anaconda3/lib/python3.8/site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/infinity/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/infinity/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: pip in /home/infinity/anaconda3/lib/python3.8/site-packages (21.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders\n",
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = pd.read_csv('intermediate_results/categoricals.csv').set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               actor_1_name      director_name\n",
       "Unnamed: 0                                    \n",
       "0               CCH Pounder      James Cameron\n",
       "1               Doug Walker        Doug Walker\n",
       "2               Johnny Depp     Gore Verbinski\n",
       "3           Christoph Waltz         Sam Mendes\n",
       "4                 Tom Hardy  Christopher Nolan\n",
       "5               Johnny Depp     Gore Verbinski"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actor_1_name</th>\n      <th>director_name</th>\n    </tr>\n    <tr>\n      <th>Unnamed: 0</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CCH Pounder</td>\n      <td>James Cameron</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Doug Walker</td>\n      <td>Doug Walker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Johnny Depp</td>\n      <td>Gore Verbinski</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Christoph Waltz</td>\n      <td>Sam Mendes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tom Hardy</td>\n      <td>Christopher Nolan</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Johnny Depp</td>\n      <td>Gore Verbinski</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "categoricals.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reseteo el index y hanblin de valores faltantes con ceros\n",
    "categoricals = categoricals.reset_index(drop=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   production_budget   title_year  aspect_ratio  duration.1  \\\n",
       "0        425000000.0  2009.000000      1.780000  178.000000   \n",
       "1        306000000.0  2002.130733      2.126976  108.577186   \n",
       "2        300000000.0  2007.000000      2.350000  169.000000   \n",
       "3        300000000.0  2015.000000      2.350000  148.000000   \n",
       "4        275000000.0  2012.000000      2.350000  164.000000   \n",
       "\n",
       "   cast_total_facebook_likes        budget  imdb_score  \n",
       "0                     4834.0  2.370000e+08         7.9  \n",
       "1                      143.0  4.045539e+07         7.1  \n",
       "2                    48350.0  3.000000e+08         7.1  \n",
       "3                    11700.0  2.450000e+08         6.8  \n",
       "4                   106759.0  2.500000e+08         8.5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>production_budget</th>\n      <th>title_year</th>\n      <th>aspect_ratio</th>\n      <th>duration.1</th>\n      <th>cast_total_facebook_likes</th>\n      <th>budget</th>\n      <th>imdb_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>425000000.0</td>\n      <td>2009.000000</td>\n      <td>1.780000</td>\n      <td>178.000000</td>\n      <td>4834.0</td>\n      <td>2.370000e+08</td>\n      <td>7.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>306000000.0</td>\n      <td>2002.130733</td>\n      <td>2.126976</td>\n      <td>108.577186</td>\n      <td>143.0</td>\n      <td>4.045539e+07</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300000000.0</td>\n      <td>2007.000000</td>\n      <td>2.350000</td>\n      <td>169.000000</td>\n      <td>48350.0</td>\n      <td>3.000000e+08</td>\n      <td>7.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>300000000.0</td>\n      <td>2015.000000</td>\n      <td>2.350000</td>\n      <td>148.000000</td>\n      <td>11700.0</td>\n      <td>2.450000e+08</td>\n      <td>6.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>275000000.0</td>\n      <td>2012.000000</td>\n      <td>2.350000</td>\n      <td>164.000000</td>\n      <td>106759.0</td>\n      <td>2.500000e+08</td>\n      <td>8.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_binenc = pd.concat([X,categoricals],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   production_budget   title_year  aspect_ratio  duration.1  \\\n",
       "0        425000000.0  2009.000000      1.780000  178.000000   \n",
       "1        306000000.0  2002.130733      2.126976  108.577186   \n",
       "2        300000000.0  2007.000000      2.350000  169.000000   \n",
       "3        300000000.0  2015.000000      2.350000  148.000000   \n",
       "4        275000000.0  2012.000000      2.350000  164.000000   \n",
       "\n",
       "   cast_total_facebook_likes        budget  imdb_score     actor_1_name  \\\n",
       "0                     4834.0  2.370000e+08         7.9      CCH Pounder   \n",
       "1                      143.0  4.045539e+07         7.1      Doug Walker   \n",
       "2                    48350.0  3.000000e+08         7.1      Johnny Depp   \n",
       "3                    11700.0  2.450000e+08         6.8  Christoph Waltz   \n",
       "4                   106759.0  2.500000e+08         8.5        Tom Hardy   \n",
       "\n",
       "       director_name  \n",
       "0      James Cameron  \n",
       "1        Doug Walker  \n",
       "2     Gore Verbinski  \n",
       "3         Sam Mendes  \n",
       "4  Christopher Nolan  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>production_budget</th>\n      <th>title_year</th>\n      <th>aspect_ratio</th>\n      <th>duration.1</th>\n      <th>cast_total_facebook_likes</th>\n      <th>budget</th>\n      <th>imdb_score</th>\n      <th>actor_1_name</th>\n      <th>director_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>425000000.0</td>\n      <td>2009.000000</td>\n      <td>1.780000</td>\n      <td>178.000000</td>\n      <td>4834.0</td>\n      <td>2.370000e+08</td>\n      <td>7.9</td>\n      <td>CCH Pounder</td>\n      <td>James Cameron</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>306000000.0</td>\n      <td>2002.130733</td>\n      <td>2.126976</td>\n      <td>108.577186</td>\n      <td>143.0</td>\n      <td>4.045539e+07</td>\n      <td>7.1</td>\n      <td>Doug Walker</td>\n      <td>Doug Walker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300000000.0</td>\n      <td>2007.000000</td>\n      <td>2.350000</td>\n      <td>169.000000</td>\n      <td>48350.0</td>\n      <td>3.000000e+08</td>\n      <td>7.1</td>\n      <td>Johnny Depp</td>\n      <td>Gore Verbinski</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>300000000.0</td>\n      <td>2015.000000</td>\n      <td>2.350000</td>\n      <td>148.000000</td>\n      <td>11700.0</td>\n      <td>2.450000e+08</td>\n      <td>6.8</td>\n      <td>Christoph Waltz</td>\n      <td>Sam Mendes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>275000000.0</td>\n      <td>2012.000000</td>\n      <td>2.350000</td>\n      <td>164.000000</td>\n      <td>106759.0</td>\n      <td>2.500000e+08</td>\n      <td>8.5</td>\n      <td>Tom Hardy</td>\n      <td>Christopher Nolan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "X_binenc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODIFICAR CATEGORIAS\n",
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(cols=['actor_1_name','director_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4104, 31)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "encoder.fit_transform(X_binenc).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binenc = encoder.fit_transform(X_binenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb_train, Xb_test, y_train, y_test = train_test_split(X_binenc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = (Xb_train[X.columns],Xb_test[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binenc = Lasso()\n",
    "model = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "model_binenc.fit(Xb_train,y_train)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.51155716036857\n0.5176042892651173\n"
     ]
    }
   ],
   "source": [
    "print(model_binenc.score(Xb_test,y_test))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentamos el rendimiento de nuestro algoritmo pero no de forma significativa. Mantengamos entonces la dimensionalidad de nuestro espacio de features baja, y vamos a buscar modelos más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conocimiento experto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  Una grán parte del diseño de las features pasa por un **conocimiento espécifico del dominio en el que se esta trabajando**. <br>\n",
    "  Por ejemplo para analizar una imagen nuestro cerebro no se concentra en los millones de pixeles de una imagen, pero sólo en algunos relevantes como los de los contornos. Durante un buen tiempo **los sistemas de visión de computadores encodeaban features que traducían este conocimiento experto (contornos).** <br>\n",
    "  Una de las únicas formas de obtener este conocimiento de forma sistemática es ir a bucear en repositorios de papers de Machine Learning como Arxiv, y estudiar la investigación que se ha hecho sobre el dominio específico.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más datos de calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nada le gana conseguir más datos que sean encodeables en features de calidad.\n",
    "\n",
    "_**Píramide de Maslow del Machine Learning**_\n",
    "\n",
    "<img src=\"img/maslow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contamos con la base de datos de ganancias de las péliculas el primer fin de semana de exhibición, así como la cantidad de cines en la que fue estrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                  movie_title  opening_gross  screens\n",
       "0           0       10 Days in a Madhouse          2451.0     10.0\n",
       "1           1  10 Things I Hate About You       8330681.0   2271.0\n",
       "2           2              102 Dalmatians      19883351.0   2704.0\n",
       "3           3                   12 Rounds       5329240.0   2331.0\n",
       "4           4            12 Years a Slave        923715.0     19.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>movie_title</th>\n      <th>opening_gross</th>\n      <th>screens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10 Days in a Madhouse</td>\n      <td>2451.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>10 Things I Hate About You</td>\n      <td>8330681.0</td>\n      <td>2271.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>102 Dalmatians</td>\n      <td>19883351.0</td>\n      <td>2704.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>12 Rounds</td>\n      <td>5329240.0</td>\n      <td>2331.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>12 Years a Slave</td>\n      <td>923715.0</td>\n      <td>19.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "pd.read_csv('opening_df.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes mejorar considerablemente nuestra predicción?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}